### Задание

1. Создает 50 zip-архивов, в каждом 100 xml файлов со случайными данными следующей структуры:

```
<root>
<var name='id' value='<случайное уникальное строковое значение>'/>
<var name='level' value='<случайное число от 1 до 100>'/>
<objects>
<object name='<случайное строковое значение>'/>
<object name='<случайное строковое значение>'/>
…
</objects>
</root>
```

В тэге objects случайное число (от 1 до 10) вложенных тэгов object.

2. Обрабатывает директорию с полученными zip архивами, разбирает вложенные xml файлы и формирует 2 csv файла:

Первый: id, level - по одной строке на каждый xml файл

Второй: id, object_name - по отдельной строке для каждого тэга object (получится от 1 до 10 строк на каждый xml файл)

 
Очень желательно сделать так, чтобы задание 2 эффективно использовало ресурсы многоядерного процессора. 

Также желательно чтобы программа работала быстро.

### Мой комментарий

`app.py` - Это первая часть задания

`xml2csv.py` - Вторая

C парсингом XML решил не велосипедть и использовать `xml.etree.ElementTree`. Так что без него не заработает

В данной версии мы геренирируем всего 2 csv файла для всех xml
т.к. XML у секций значения случайны, но не уникальны, то в данной реализации могут быть коллизии т.к. для формирования мы используем словари
пример второго csv файла:
```
maLryz jxIteh
jtzKlc Bgklrt
ZvFPFB nlERio
CevoJO nlERio
wcjZtl nlERio
pGwEou dkfWjd
ttGVYb dkfWjd
yCvCUs dkfWjd
```


Требуется уточнение самого задания т.к. не сосвсем ясно 2 csv всего или 2 csv для каждого файла.
Пока сделал как если бы 2 csv всего.



Никаких оптимизаций по производительности в данной версии нет.